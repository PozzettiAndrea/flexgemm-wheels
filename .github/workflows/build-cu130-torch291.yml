name: Build CUDA 13.0 + PyTorch 2.9.1

on:
  push:
    branches: [main]
    paths:
      - '.github/workflows/build-cu130-torch291.yml'
    tags: ['v*']
  workflow_dispatch:

env:
  CUDA_VERSION: '13.0'
  CUDA_SHORT: '130'
  PYTORCH_VERSION: '2.9.1'
  TORCH_SHORT: '291'
  TORCH_MM: '29'
  TORCH_CUDA_ARCH_LIST: '7.5;8.0;8.6;8.9;9.0;10.0;12.0'

jobs:
  build-linux:
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        python: ['3.10', '3.11', '3.12', '3.13']

    steps:
      - uses: actions/checkout@v4

      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo apt-get clean
          df -h

      - name: Setup Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Install CUDA toolkit
        run: |
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          sudo apt-get update
          sudo apt-get install -y \
            cuda-nvcc-13-0 \
            cuda-cudart-dev-13-0 \
            libcublas-dev-13-0 \
            libcusparse-dev-13-0 \
            libcurand-dev-13-0 \
            libcufft-dev-13-0 \
            libcusolver-dev-13-0 \
            cuda-nvtx-13-0
          echo "/usr/local/cuda-13.0/bin" >> $GITHUB_PATH
          echo "CUDA_HOME=/usr/local/cuda-13.0" >> $GITHUB_ENV
          echo "CUDA_PATH=/usr/local/cuda-13.0" >> $GITHUB_ENV

      - name: Install CUDA PyTorch and build tools
        run: |
          pip install --no-cache-dir torch==${{ env.PYTORCH_VERSION }} --index-url https://download.pytorch.org/whl/cu130
          pip install --no-cache-dir wheel setuptools ninja numpy triton

      - name: Verify setup
        run: |
          nvcc --version
          python -c "import torch; print(f'PyTorch: {torch.__version__}')"
          echo "CUDA_HOME=$CUDA_HOME"

      - name: Clone and build FlexGEMM
        run: |
          export CUDA_HOME=/usr/local/cuda-13.0
          export CUDA_PATH=/usr/local/cuda-13.0
          export FORCE_CUDA=1
          export TORCH_CUDA_ARCH_LIST="${{ env.TORCH_CUDA_ARCH_LIST }}"
          export CXXFLAGS="-D_GLIBCXX_USE_CXX11_ABI=1"
          git config --global url."https://github.com/".insteadOf "git@github.com:"
          git clone https://github.com/JeffreyXiang/FlexGEMM.git --recursive
          cd FlexGEMM
          # Clean pre-existing wheels from repo to avoid artifact conflicts
          rm -rf dist/*
          # Patch pyproject.toml: make triton conditional for Windows compatibility
          sed -i 's/"triton>=3.2.0"/"triton>=3.2.0; platform_system != '\''Windows'\''", "triton-windows>=3.2.0; platform_system == '\''Windows'\''"/g' pyproject.toml
          # Patch setup.py to add CXX11 ABI flag (CXXFLAGS env var is not picked up by PyTorch build)
          sed -i 's/"cxx": \["-O3", "-std=c++17"\]/"cxx": ["-O3", "-std=c++17", "-D_GLIBCXX_USE_CXX11_ABI=1"]/' setup.py
          pip install --no-build-isolation .
          python setup.py bdist_wheel
          # Rename wheel with CUDA+PyTorch suffix
          cd dist && for f in *.whl; do mv "$f" "$(echo $f | sed 's/-cp/+cu${{ env.CUDA_SHORT }}torch${{ env.TORCH_MM }}-cp/')"; done && cd ..
          ls -la dist/

      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: flexgemm-linux-cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}-py${{ matrix.python }}
          path: FlexGEMM/dist/*.whl
          retention-days: 7

  build-windows:
    runs-on: windows-2022
    strategy:
      fail-fast: false
      matrix:
        python: ['3.10', '3.11', '3.12', '3.13']

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Download CUDA network installer
        shell: powershell
        run: |
          $installerUrl = "https://developer.download.nvidia.com/compute/cuda/13.0.0/network_installers/cuda_13.0.0_windows_network.exe"
          Write-Host "Downloading CUDA 13.0 network installer..."
          Invoke-WebRequest -Uri $installerUrl -OutFile "cuda_installer.exe" -UseBasicParsing
          Write-Host "Download complete, size: $((Get-Item cuda_installer.exe).Length) bytes"

      - name: Install CUDA toolkit
        shell: powershell
        run: |
          Write-Host "Installing CUDA toolkit..."
          # crt_13.0 provides crt/host_config.h
          Start-Process -FilePath "cuda_installer.exe" -ArgumentList "-s", "-n", "nvcc_13.0", "crt_13.0", "cudart_13.0", "cusparse_dev_13.0", "cublas_dev_13.0", "curand_dev_13.0", "cufft_dev_13.0", "cusolver_dev_13.0", "thrust_13.0", "nvtx_13.0" -Wait -NoNewWindow
          $cudaPath = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
          if (Test-Path "$cudaPath\bin\nvcc.exe") {
            Write-Host "CUDA installed successfully"
          } else {
            Write-Host "WARNING: nvcc.exe not found"
            Get-ChildItem "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\" -ErrorAction SilentlyContinue
          }
          echo "$cudaPath\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          echo "CUDA_HOME=$cudaPath" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          echo "CUDA_PATH=$cudaPath" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append

      - name: Symlink CCCL headers for CUDA 13.0
        shell: cmd
        run: |
          REM CUDA 13.0 moved CUB/Thrust to include\cccl\ - create symlinks for compatibility
          cd "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include"
          if exist cccl\cub mklink /D cub cccl\cub
          if exist cccl\thrust mklink /D thrust cccl\thrust
          if exist cccl\cuda mklink /D cuda\std cccl\cuda\std
          dir

      - name: Install CUDA PyTorch and build tools
        shell: bash
        run: |
          pip install --no-cache-dir torch==${{ env.PYTORCH_VERSION }} --index-url https://download.pytorch.org/whl/cu130
          pip install --no-cache-dir wheel setuptools ninja numpy

      - name: Patch PyTorch header for Windows MSVC bug
        shell: bash
        run: |
          # Fix for https://github.com/pytorch/pytorch/issues/166123
          TORCH_PATH=$(python -c "import torch; print(torch.__path__[0])")
          HEADER_FILE="$TORCH_PATH/include/torch/csrc/dynamo/compiled_autograd.h"
          if [ -f "$HEADER_FILE" ]; then
            echo "Patching $HEADER_FILE for MSVC std:: ambiguity bug"
            sed -i 's/} else if constexpr (::std::is_same_v<T, ::std::string>) {/\/\/ PATCHED: } else if constexpr (::std::is_same_v<T, ::std::string>) {/' "$HEADER_FILE"
            sed -i 's/return at::StringType::get();/\/\/ PATCHED: return at::StringType::get();/' "$HEADER_FILE"
            echo "Patch applied successfully"
          else
            echo "Warning: Header file not found at $HEADER_FILE"
          fi

      - name: Verify setup
        run: |
          nvcc --version
          python -c "import torch; print(f'PyTorch: {torch.__version__}')"

      - name: Clone FlexGEMM
        shell: bash
        run: |
          git config --global url."https://github.com/".insteadOf "git@github.com:"
          git clone https://github.com/JeffreyXiang/FlexGEMM.git --recursive

          # Clean pre-existing wheels from repo to avoid artifact conflicts
          rm -rf FlexGEMM/dist/*

      - name: Patch pyproject.toml for triton-windows
        shell: bash
        run: |
          cd FlexGEMM
          sed -i 's/"triton>=3.2.0"/"triton>=3.2.0; platform_system != '\''Windows'\''", "triton-windows>=3.2.0; platform_system == '\''Windows'\''"/g' pyproject.toml

      - name: Patch for Windows uint
        shell: powershell
        run: |
          $file = "FlexGEMM/flex_gemm/kernels/cuda/spconv/neighbor_map.cu"
          $content = Get-Content $file -Raw
          $patch = "typedef unsigned int uint;`n"
          $content = $patch + $content
          Set-Content $file $content

      - name: Patch setup.py for debug symbols
        shell: bash
        run: |
          cd FlexGEMM
          python << 'PATCH_SCRIPT'
          with open('setup.py', 'r') as f:
              content = f.read()

          # Replace cxx compile args for MSVC with debug symbols (line-by-line, indentation-agnostic)
          content = content.replace(
              '"cxx": ["-O3", "-std=c++17"]',
              '"cxx": ["/O2", "/Zi", "/std:c++17", "/EHsc"]'
          )

          # Add -Xcompiler /Zi to nvcc args
          content = content.replace(
              '"nvcc": ["-O3","-std=c++17"] + cc_flag,',
              '"nvcc": ["-O3","-std=c++17", "-Xcompiler", "/Zi"] + cc_flag,'
          )

          # Add extra_link_args for debug info (match the closing of extra_compile_args)
          content = content.replace(
              '+ cc_flag,\n            }',
              '+ cc_flag,\n            },\n            extra_link_args=["/DEBUG:FULL"]'
          )

          with open('setup.py', 'w') as f:
              f.write(content)

          print("Patched setup.py for MSVC debug symbols")
          PATCH_SCRIPT

      - name: Build wheel
        shell: cmd
        run: |
          cd FlexGEMM
          set "CUDA_HOME=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
          set "CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
          set FORCE_CUDA=1
          set TORCH_CUDA_ARCH_LIST=7.5;8.0;8.6;8.9;9.0;10.0;12.0
          pip install --no-build-isolation .
          python setup.py bdist_wheel
          dir dist

      - name: Rename wheel with CUDA+PyTorch suffix
        shell: powershell
        run: |
          cd FlexGEMM\dist
          Get-ChildItem *.whl | ForEach-Object {
            # Only replace the first -cp (after version), not the second one (ABI tag)
            $newname = $_.Name -replace '^([^-]+-\d+\.\d+\.\d+)-cp', '$1+cu${{ env.CUDA_SHORT }}torch${{ env.TORCH_MM }}-cp'
            Rename-Item $_.FullName $newname
          }
          Get-ChildItem

      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: flexgemm-windows-cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}-py${{ matrix.python }}
          path: FlexGEMM/dist/*.whl
          retention-days: 7

  release:
    needs: [build-linux, build-windows]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Collect wheels
        run: |
          mkdir -p wheels
          find artifacts -name "*.whl" -exec cp {} wheels/ \;
          echo "Collected wheels:"
          ls -la wheels/

      - name: Delete existing release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh release delete cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }} --yes || true

      - name: Create or update GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}
          name: CUDA ${{ env.CUDA_VERSION }} + PyTorch ${{ env.PYTORCH_VERSION }}
          body: |
            Pre-built FlexGEMM wheels for CUDA ${{ env.CUDA_VERSION }} + PyTorch ${{ env.PYTORCH_VERSION }}

            **Install:**
            ```bash
            pip install flex_gemm \
              --find-links https://pozzettiandrea.github.io/flexgemm-wheels/cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}/
            ```

            **Supported:**
            - Python: 3.10, 3.11, 3.12, 3.13
            - Platforms: Linux (x86_64), Windows (amd64)
            - GPU: RTX 20/30/40/50 series, A100, B100/B200
          files: wheels/*.whl
          fail_on_unmatched_files: true
          make_latest: false

  update-index:
    needs: [release]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4
        with:
          ref: main

      - name: Generate index.html for this release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          WHEEL_DIR="wheels/cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}"
          mkdir -p "$WHEEL_DIR"

          RELEASE_TAG="cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}"
          REPO="${{ github.repository }}"

          cat > "$WHEEL_DIR/index.html" << 'HEADER'
          <!DOCTYPE html>
          <html>
          <head>
              <title>FlexGEMM Wheels - CUDA ${{ env.CUDA_VERSION }} + PyTorch ${{ env.PYTORCH_VERSION }}</title>
              <style>
                  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
                  a { color: #0366d6; }
                  pre { background: #f6f8fa; padding: 15px; border-radius: 5px; overflow-x: auto; }
              </style>
          </head>
          <body>
          <h1>FlexGEMM Wheels</h1>
          <p><strong>CUDA ${{ env.CUDA_VERSION }} + PyTorch ${{ env.PYTORCH_VERSION }}</strong></p>
          <h2>Install</h2>
          <pre>pip install flex_gemm --find-links https://pozzettiandrea.github.io/flexgemm-wheels/cu${{ env.CUDA_SHORT }}-torch${{ env.TORCH_SHORT }}/</pre>
          <h2>Available Wheels</h2>
          HEADER

          gh release view "$RELEASE_TAG" --json assets --jq '.assets[].name' | while read -r wheel; do
            echo "<a href=\"https://github.com/$REPO/releases/download/$RELEASE_TAG/$wheel\">$wheel</a><br>" >> "$WHEEL_DIR/index.html"
          done

          cat >> "$WHEEL_DIR/index.html" << 'FOOTER'
          <p style="margin-top: 20px;"><a href="../">Back to index</a></p>
          </body>
          </html>
          FOOTER

          echo "Generated index.html:"
          cat "$WHEEL_DIR/index.html"

      - name: Commit index.html
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add wheels/
          git commit -m "Update index: CUDA ${{ env.CUDA_VERSION }} + PyTorch ${{ env.PYTORCH_VERSION }}" || echo "No changes"
          git pull --rebase origin main || true
          git push
