<!DOCTYPE html>
<html>
<head>
    <title>FlexGEMM Wheels</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
        a { color: #0366d6; }
        pre { background: #f6f8fa; padding: 15px; border-radius: 5px; overflow-x: auto; }
        ul { line-height: 2; }
    </style>
</head>
<body>
<h1>FlexGEMM Wheels</h1>
<p>Pre-built wheels for <a href="https://github.com/JeffreyXiang/FlexGEMM">FlexGEMM</a> - Efficient sparse convolution based on Triton.</p>

<h2>Available Configurations</h2>
<ul>
    <li><a href="cu124-torch251/">CUDA 12.4 + PyTorch 2.5.1</a> (Python 3.10-3.12)</li>
    <li><a href="cu126-torch260/">CUDA 12.6 + PyTorch 2.6.0</a> (Python 3.10-3.13)</li>
    <li><a href="cu126-torch280/">CUDA 12.6 + PyTorch 2.8.0</a> (Python 3.10-3.13)</li>
    <li><a href="cu128-torch280/">CUDA 12.8 + PyTorch 2.8.0</a> (Python 3.10-3.13)</li>
    <li><a href="cu128-torch291/">CUDA 12.8 + PyTorch 2.9.1</a> (Python 3.10-3.13)</li>
</ul>

<h2>Installation</h2>
<p>Choose the configuration matching your CUDA and PyTorch versions:</p>
<pre>pip install flexgemm --find-links https://pozzettiandrea.github.io/flexgemm-wheels/cu128-torch291/</pre>

<h2>Supported GPUs</h2>
<ul>
    <li>CUDA 12.4/12.6: RTX 20/30/40 series, A100</li>
    <li>CUDA 12.8: RTX 20/30/40/50 series, A100, B100/B200</li>
</ul>
</body>
</html>
